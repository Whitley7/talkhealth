{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "56f478e4-38fb-4830-ac70-c040bb9d3380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5455e3b-ee5b-4052-88cc-67a625328f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  sarcastic\n",
      "0  the only thing i get from college be a caffein...          1\n",
      "1  i love it when professor draw a big question m...          1\n",
      "2  remember the hundred email from company when c...          1\n",
      "3  today my pop pop tell me i be not force to go ...          1\n",
      "4  i do too and i also report cancun cruz not wor...          1\n",
      "                                               tweet  sarcastic\n",
      "0  size on the the toulouse team that pack be mon...          0\n",
      "1                                            pinball          0\n",
      "2  so the scottish government want people to get ...          1\n",
      "3  villainous pro tip change the device name on h...          0\n",
      "4                    i would date any of these men ðŸ¥º          0\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(r\"\\TalkHealth\\Datasets\\train_sarcasm.csv\")\n",
    "test_df = pd.read_csv(r\"\\TalkHealth\\Datasets\\test_sarcasm.csv\")\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b876fbd3-6985-4d66-887a-8437a29b209d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (3467, 2)\n",
      "Test shape: (1400, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6441e448-bbd7-475a-80b0-503be645163c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train null values tweet        1\n",
      "sarcastic    0\n",
      "dtype: int64\n",
      "Train null values tweet        0\n",
      "sarcastic    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Train null values\", train_df.isnull().sum())\n",
    "print(\"Train null values\", test_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "068f2705-4159-4e78-8c2d-ee0fd4882579",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "167393bb-496d-40a2-b0ea-75c518e7c87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sarcastic\n",
      "0    2599\n",
      "1     867\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df['sarcastic'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "736c4fe0-b838-46a2-8803-2ae923cd7a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3466.000000\n",
      "mean       18.574437\n",
      "std        11.250773\n",
      "min         1.000000\n",
      "25%        10.000000\n",
      "50%        16.000000\n",
      "75%        24.000000\n",
      "max        61.000000\n",
      "Name: tweet_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_df['tweet_length'] = train_df['tweet'].apply(lambda x: len(x.split()))\n",
    "print(train_df['tweet_length'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80f152d9-3851-4e1d-9bd7-6c749e50c7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)  \n",
    "    text = re.sub(r'@\\w+', '', text)  \n",
    "    text = re.sub(r'#', '', text) \n",
    "    text = re.sub(r'[\\U00010000-\\U0010ffff]', '', text)  \n",
    "    text = re.sub(r'[^\\w\\s.,!?]', '', text)  \n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d032059-4cab-4be8-bda0-5142eed2fb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['tweet'] = train_df['tweet'].apply(preprocess_text)\n",
    "test_df['tweet'] = test_df['tweet'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1071ffb0-1552-4e1f-bfd1-39f4e18412a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "majority = train_df[train_df['sarcastic'] == 0]\n",
    "minority = train_df[train_df['sarcastic'] == 1]\n",
    "minority_upsampled = resample(minority, replace=True, n_samples=len(majority), random_state=42)\n",
    "train_df_balanced = pd.concat([majority, minority_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3b19cbec-b07f-4273-baad-e69ef37d5c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_df_balanced['tweet'].tolist(),\n",
    "    train_df_balanced['sarcastic'].tolist(),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=train_df_balanced['sarcastic']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "74cd509f-1352-4854-9977-88fb8b3d1dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1    2079\n",
      "0    2079\n",
      "Name: count, dtype: int64\n",
      "Val: 0    520\n",
      "1    520\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\", pd.Series(train_labels).value_counts())\n",
    "print(\"Val:\", pd.Series(val_labels).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "64445282-f7a2-4ddc-9604-a6ad3309bbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "class IronyDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_len,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7cff8a56-b7ac-4679-a58e-f0ae8cf5443d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilroberta-base')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('distilroberta-base', num_labels=2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "09910ef8-b569-4eb4-be8a-19f7fa5307eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = IronyDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = IronyDataset(val_texts, val_labels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "86381c9b-d408-4af2-ba78-3bb4078529f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    labels = p.label_ids\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {'accuracy': acc, 'f1': f1, 'precision': precision, 'recall': recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "550d48e1-693a-405c-8825-456e39eb0c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results_distilroberta',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    logging_dir='./logs_distilroberta',\n",
    "    logging_steps=10,\n",
    "    eval_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=2e-5,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "05ddbe77-95ea-4b31-a086-b4c8e93ab816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='390' max='390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [390/390 04:21, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.671600</td>\n",
       "      <td>0.658639</td>\n",
       "      <td>0.617308</td>\n",
       "      <td>0.595781</td>\n",
       "      <td>0.649060</td>\n",
       "      <td>0.617308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.473700</td>\n",
       "      <td>0.527751</td>\n",
       "      <td>0.734615</td>\n",
       "      <td>0.734600</td>\n",
       "      <td>0.734671</td>\n",
       "      <td>0.734615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.398500</td>\n",
       "      <td>0.497694</td>\n",
       "      <td>0.771154</td>\n",
       "      <td>0.770848</td>\n",
       "      <td>0.772610</td>\n",
       "      <td>0.771154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=390, training_loss=0.5546855095105293, metrics={'train_runtime': 262.2815, 'train_samples_per_second': 47.56, 'train_steps_per_second': 1.487, 'total_flos': 413099582708736.0, 'train_loss': 0.5546855095105293, 'epoch': 3.0})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "474cf7a4-5443-4c4d-8843-fa46ba7abfcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./irony_detector_distilroberta\\\\tokenizer_config.json',\n",
       " './irony_detector_distilroberta\\\\special_tokens_map.json',\n",
       " './irony_detector_distilroberta\\\\vocab.json',\n",
       " './irony_detector_distilroberta\\\\merges.txt',\n",
       " './irony_detector_distilroberta\\\\added_tokens.json',\n",
       " './irony_detector_distilroberta\\\\tokenizer.json')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('./irony_detector_distilroberta')\n",
    "tokenizer.save_pretrained('./irony_detector_distilroberta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d67372b4-175e-4939-8485-ed79d1cfe3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = IronyDataset(test_df['tweet'].tolist(), test_df['sarcastic'].tolist(), tokenizer)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a4fa61d2-2a45-479a-895d-aca4f3231ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.eval()\n",
    "preds, labels = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        batch_labels = batch['labels'].numpy()\n",
    "        outputs = trainer.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        probs = torch.softmax(outputs.logits, dim=1)\n",
    "        batch_preds = (probs[:, 1] > 0.4).long().cpu().numpy()\n",
    "        preds.extend(batch_preds)\n",
    "        labels.extend(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "63fd2795-3a09-4f59-8beb-4ac43773a606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Roberta Accuracy: 0.5621\n",
      "Roberta Precision: 0.7834\n",
      "Roberta Recall: 0.5621\n",
      "Roberta F1 Score: 0.6277\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8847    0.5625    0.6877      1200\n",
      "           1     0.1758    0.5600    0.2676       200\n",
      "\n",
      "    accuracy                         0.5621      1400\n",
      "   macro avg     0.5302    0.5613    0.4777      1400\n",
      "weighted avg     0.7834    0.5621    0.6277      1400\n",
      "\n",
      "Confusion Matrix:\n",
      "[[675 525]\n",
      " [ 88 112]]\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "acc = accuracy_score(labels, preds)\n",
    "print(f\"\\nRoberta Accuracy: {acc:.4f}\")\n",
    "print(f\"Roberta Precision: {precision:.4f}\")\n",
    "print(f\"Roberta Recall: {recall:.4f}\")\n",
    "print(f\"Roberta F1 Score: {f1:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(labels, preds, digits=4))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(labels, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635cab11-eb5e-425c-a1be-ac4c7293a775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcc1f25-8939-4722-91f9-442441cd0400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2725f4-336c-495b-b7cc-484d9132ca49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9b779d-d942-4655-bc8e-f2ad577352d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec16ed0-166a-48c6-b293-ad64066529d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff608288-4cf4-4160-a49a-fe38239cd1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8bd070-e843-4df6-8b34-8da1aecb3a54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "40dae7cd-e938-4778-9eba-96562c69da55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features=10000)\n",
    "X_train_tfidf = vectorizer.fit_transform(train_df_balanced['tweet'])\n",
    "y_train = train_df_balanced['sarcastic']\n",
    "\n",
    "X_test_tfidf = vectorizer.transform(test_df['tweet'])\n",
    "y_test = test_df['sarcastic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3376ce18-292e-4658-a0a7-03161b16b316",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "svm_model = LinearSVC(class_weight='balanced')\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "svm_preds = svm_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "80f4a1e2-87a5-4d5f-8b67-b4ff29019eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.7457\n",
      "SVM Precision: 0.7654\n",
      "SVM Recall: 0.7457\n",
      "SVM F1 Score: 0.7551\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8638    0.8350    0.8492      1200\n",
      "           1     0.1750    0.2100    0.1909       200\n",
      "\n",
      "    accuracy                         0.7457      1400\n",
      "   macro avg     0.5194    0.5225    0.5200      1400\n",
      "weighted avg     0.7654    0.7457    0.7551      1400\n",
      "\n",
      "SVM Confusion Matrix:\n",
      "[[1002  198]\n",
      " [ 158   42]]\n"
     ]
    }
   ],
   "source": [
    "svm_precision, svm_recall, svm_f1, _ = precision_recall_fscore_support(y_test, svm_preds, average='weighted')\n",
    "svm_acc = accuracy_score(y_test, svm_preds)\n",
    "print(f\"SVM Accuracy: {svm_acc:.4f}\")\n",
    "print(f\"SVM Precision: {svm_precision:.4f}\")\n",
    "print(f\"SVM Recall: {svm_recall:.4f}\")\n",
    "print(f\"SVM F1 Score: {svm_f1:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, svm_preds, digits=4))\n",
    "print(\"SVM Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, svm_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hateBERT)",
   "language": "python",
   "name": "hatebert-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
