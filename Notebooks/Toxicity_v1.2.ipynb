{
 "cells": [
  {
   "cell_type": "code",
   "id": "a949d8d8-6947-469a-9d56-ee719f4f413a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T02:46:08.992583Z",
     "start_time": "2025-05-31T02:46:07.351016Z"
    }
   },
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "c37078f4-b318-4e21-9677-bac0ca573cb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T02:46:00.401111Z",
     "start_time": "2025-05-31T02:45:36.786326Z"
    }
   },
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from tqdm import tqdm\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "0aff8726-80ec-446b-9435-3ee886f6df29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T02:46:45.360927Z",
     "start_time": "2025-05-31T02:46:44.130765Z"
    }
   },
   "source": [
    "# 1. Load and Prepare Dataset\n",
    "\n",
    "df_train = pd.read_csv(r\"\\TalkHealth\\Datasets\\train.csv\\train.csv\")\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    leet_dict = {'0': 'o', '1': 'i', '3': 'e', '4': 'a', '5': 's', '7': 't'}\n",
    "    for leet, letter in leet_dict.items():\n",
    "        text = text.replace(leet, letter)\n",
    "    text = re.sub(r'(\\w)\\.(\\w)', r'\\1\\2', text)\n",
    "    text = ''.join(c for c in text if c in string.printable)\n",
    "    text = re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Clean comments\n",
    "df_train['comment_text'] = df_train['comment_text'].apply(clean_text)\n",
    "\n",
    "# Prepare labels\n",
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "#Subsample to 20k for quick training\n",
    "df_train = df_train.sample(n=20000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Stratified split\n",
    "stratify_labels = df_train[label_cols].sum(axis=1)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    df_train['comment_text'].tolist(),\n",
    "    df_train[label_cols].values,\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    stratify=stratify_labels\n",
    ")\n",
    "\n",
    "# Create a small warmup subset (5k samples)\n",
    "df_warmup = df_train.sample(n=5000, random_state=123).reset_index(drop=True)\n",
    "X_warmup = df_warmup['comment_text'].tolist()\n",
    "Y_warmup = df_warmup[label_cols].values\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "faacc5c5-0056-4f33-8a0e-4e9a8d47f836",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load model and tokenizer (distilroberta-base)\n",
    "\n",
    "model_checkpoint = \"distilroberta-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=6)\n",
    "\n",
    "# Dataset preparation\n",
    "\n",
    "class ToxicCommentsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=256,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(label, dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "warmup_dataset = ToxicCommentsDataset(X_warmup, Y_warmup, tokenizer)\n",
    "train_dataset = ToxicCommentsDataset(X_train, Y_train, tokenizer)\n",
    "val_dataset = ToxicCommentsDataset(X_val, Y_val, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a3bd430b-7b41-464c-9b0a-4a8e64eea526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for evaluation\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions\n",
    "    preds = (preds > 0.5).astype(int)\n",
    "\n",
    "    micro_f1 = f1_score(labels, preds, average='micro', zero_division=0)\n",
    "    macro_f1 = f1_score(labels, preds, average='macro', zero_division=0)\n",
    "    micro_precision = precision_score(labels, preds, average='micro', zero_division=0)\n",
    "    macro_precision = precision_score(labels, preds, average='macro', zero_division=0)\n",
    "    micro_recall = recall_score(labels, preds, average='micro', zero_division=0)\n",
    "    macro_recall = recall_score(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    return {\n",
    "        'micro_f1': micro_f1,\n",
    "        'macro_f1': macro_f1,\n",
    "        'micro_precision': micro_precision,\n",
    "        'macro_precision': macro_precision,\n",
    "        'micro_recall': micro_recall,\n",
    "        'macro_recall': macro_recall\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "40977ce6-cf18-4bbf-a9c4-9716a528b528",
   "metadata": {},
   "source": [
    "# Warm-up training arguments\n",
    "\n",
    "warmup_training_args = TrainingArguments(\n",
    "    output_dir=\"./warmup_checkpoint\",\n",
    "    eval_strategy=\"no\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./warmup_logs',\n",
    "    save_total_limit=1,\n",
    ")\n",
    "\n",
    "# Warm-up trainer initialization and training\n",
    "\n",
    "warmup_trainer = Trainer(\n",
    "    model=model,\n",
    "    args=warmup_training_args,\n",
    "    train_dataset=warmup_dataset,\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "warmup_trainer.train()\n",
    "\n",
    "model.save_pretrained(\"./warmup_distilroberta_model\")\n",
    "tokenizer.save_pretrained(\"./warmup_distilroberta_model\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [313/313 06:14, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "",
   "id": "76b52134-968e-4cbe-bcde-86a03339556e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ac771cb8-ea64-45b0-b429-43317a20cf7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load warm-up model for full fine-tuning\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"./warmup_distilroberta_model\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "id": "df760bc8-b0e8-4ec9-bb53-835f1814460e",
   "metadata": {},
   "source": [
    "# Full training arguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./warmup_distilroberta_model\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_steps=100,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_dir='./final_logs',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"macro_f1\",\n",
    "    greater_is_better=True,\n",
    "    save_total_limit=2,\n",
    "    fp16=True\n",
    ")\n",
    "# Full fine-tuning trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "model.save_pretrained(\"./distilroberta_trained\")\n",
    "tokenizer.save_pretrained(\"./distilroberta_trained\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c57f0fe1-e1ed-4abc-a01d-96a03d724e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='201' max='3375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 201/3375 03:56 < 1:02:49, 0.84 it/s, Epoch 0.18/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Macro Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.043752</td>\n",
       "      <td>0.750623</td>\n",
       "      <td>0.391622</td>\n",
       "      <td>0.820163</td>\n",
       "      <td>0.406743</td>\n",
       "      <td>0.691954</td>\n",
       "      <td>0.377593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.044952</td>\n",
       "      <td>0.752451</td>\n",
       "      <td>0.393293</td>\n",
       "      <td>0.805774</td>\n",
       "      <td>0.404392</td>\n",
       "      <td>0.705747</td>\n",
       "      <td>0.383399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[91], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m trainer\u001B[38;5;241m.\u001B[39mtrain()\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:2245\u001B[0m, in \u001B[0;36mTrainer.train\u001B[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[0;32m   2243\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[0;32m   2244\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2245\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m inner_training_loop(\n\u001B[0;32m   2246\u001B[0m         args\u001B[38;5;241m=\u001B[39margs,\n\u001B[0;32m   2247\u001B[0m         resume_from_checkpoint\u001B[38;5;241m=\u001B[39mresume_from_checkpoint,\n\u001B[0;32m   2248\u001B[0m         trial\u001B[38;5;241m=\u001B[39mtrial,\n\u001B[0;32m   2249\u001B[0m         ignore_keys_for_eval\u001B[38;5;241m=\u001B[39mignore_keys_for_eval,\n\u001B[0;32m   2250\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:2627\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[0;32m   2625\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mepoch \u001B[38;5;241m=\u001B[39m epoch \u001B[38;5;241m+\u001B[39m (step \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m steps_skipped) \u001B[38;5;241m/\u001B[39m steps_in_epoch\n\u001B[0;32m   2626\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_step_end(args, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n\u001B[1;32m-> 2627\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_log_save_evaluate(\n\u001B[0;32m   2628\u001B[0m         tr_loss,\n\u001B[0;32m   2629\u001B[0m         grad_norm,\n\u001B[0;32m   2630\u001B[0m         model,\n\u001B[0;32m   2631\u001B[0m         trial,\n\u001B[0;32m   2632\u001B[0m         epoch,\n\u001B[0;32m   2633\u001B[0m         ignore_keys_for_eval,\n\u001B[0;32m   2634\u001B[0m         start_time,\n\u001B[0;32m   2635\u001B[0m         learning_rate\u001B[38;5;241m=\u001B[39mlearning_rate,\n\u001B[0;32m   2636\u001B[0m     )\n\u001B[0;32m   2637\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2638\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_substep_end(args, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:3103\u001B[0m, in \u001B[0;36mTrainer._maybe_log_save_evaluate\u001B[1;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001B[0m\n\u001B[0;32m   3100\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol\u001B[38;5;241m.\u001B[39mshould_save \u001B[38;5;241m=\u001B[39m is_new_best_metric\n\u001B[0;32m   3102\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol\u001B[38;5;241m.\u001B[39mshould_save:\n\u001B[1;32m-> 3103\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_save_checkpoint(model, trial)\n\u001B[0;32m   3104\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_save(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:3200\u001B[0m, in \u001B[0;36mTrainer._save_checkpoint\u001B[1;34m(self, model, trial)\u001B[0m\n\u001B[0;32m   3198\u001B[0m run_dir \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_output_dir(trial\u001B[38;5;241m=\u001B[39mtrial)\n\u001B[0;32m   3199\u001B[0m output_dir \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(run_dir, checkpoint_folder)\n\u001B[1;32m-> 3200\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave_model(output_dir, _internal_call\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m   3202\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39msave_strategy \u001B[38;5;129;01min\u001B[39;00m [SaveStrategy\u001B[38;5;241m.\u001B[39mSTEPS, SaveStrategy\u001B[38;5;241m.\u001B[39mEPOCH] \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mbest_global_step:\n\u001B[0;32m   3203\u001B[0m     best_checkpoint_folder \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mPREFIX_CHECKPOINT_DIR\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m-\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mbest_global_step\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:3902\u001B[0m, in \u001B[0;36mTrainer.save_model\u001B[1;34m(self, output_dir, _internal_call)\u001B[0m\n\u001B[0;32m   3899\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_wrapped\u001B[38;5;241m.\u001B[39msave_checkpoint(output_dir)\n\u001B[0;32m   3901\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mshould_save:\n\u001B[1;32m-> 3902\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_save(output_dir)\n\u001B[0;32m   3904\u001B[0m \u001B[38;5;66;03m# Push to the Hub when `save_model` is called by the user.\u001B[39;00m\n\u001B[0;32m   3905\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mpush_to_hub \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _internal_call:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:4006\u001B[0m, in \u001B[0;36mTrainer._save\u001B[1;34m(self, output_dir, state_dict)\u001B[0m\n\u001B[0;32m   4004\u001B[0m             torch\u001B[38;5;241m.\u001B[39msave(state_dict, os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(output_dir, WEIGHTS_NAME))\n\u001B[0;32m   4005\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 4006\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39msave_pretrained(\n\u001B[0;32m   4007\u001B[0m         output_dir, state_dict\u001B[38;5;241m=\u001B[39mstate_dict, safe_serialization\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39msave_safetensors\n\u001B[0;32m   4008\u001B[0m     )\n\u001B[0;32m   4010\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocessing_class \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   4011\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocessing_class\u001B[38;5;241m.\u001B[39msave_pretrained(output_dir)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:3564\u001B[0m, in \u001B[0;36mPreTrainedModel.save_pretrained\u001B[1;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001B[0m\n\u001B[0;32m   3559\u001B[0m     gc\u001B[38;5;241m.\u001B[39mcollect()\n\u001B[0;32m   3561\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m safe_serialization:\n\u001B[0;32m   3562\u001B[0m     \u001B[38;5;66;03m# At some point we will need to deal better with save_function (used for TPU and other distributed\u001B[39;00m\n\u001B[0;32m   3563\u001B[0m     \u001B[38;5;66;03m# joyfulness), but for now this enough.\u001B[39;00m\n\u001B[1;32m-> 3564\u001B[0m     safe_save_file(shard, os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(save_directory, shard_file), metadata\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mformat\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m})\n\u001B[0;32m   3565\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   3566\u001B[0m     save_function(shard, os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(save_directory, shard_file))\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a5b2a310-bd21-41b7-958f-1fb6a56da692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_checkpoint = './distilroberta_trained'\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilroberta-base')\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)\n",
    "model.eval()\n",
    "\n",
    "# Load test data\n",
    "df_test = pd.read_csv(r\"\\TalkHealth\\Datasets\\test.csv\\test.csv\")\n",
    "df_labels = pd.read_csv(r\"\\TalkHealth\\Datasets\\test.csv\\test.csv\")\n",
    "\n",
    "\n",
    "# Some test labels may be -1 (unlabeled), so filter\n",
    "df = df_test.merge(df_labels, on='id')\n",
    "df = df[df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].min(axis=1) >= 0]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "stratify_labels = df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1)\n",
    "df_sampled, _ = train_test_split(\n",
    "    df,\n",
    "    train_size=20000,\n",
    "    random_state=42,\n",
    "    stratify=stratify_labels\n",
    ")\n",
    "df = df_sampled.reset_index(drop=True)\n",
    "\n",
    "texts = df['comment_text'].astype(str).apply(clean_text).tolist()\n",
    "labels = df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0db37752-a01d-4292-a59b-4a18e974c711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test dataset\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length=256):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "# Prepare dataset and dataloader\n",
    "test_dataset = TestDataset(texts, tokenizer)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "410884a9-5ba1-4645-8a98-158645d5e44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   0%|‚ñè                                                                    | 4/1250 [00:02<15:14,  1.36it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[119], line 23\u001B[0m\n\u001B[0;32m     20\u001B[0m         outputs \u001B[38;5;241m=\u001B[39m model(input_ids\u001B[38;5;241m=\u001B[39minput_ids, attention_mask\u001B[38;5;241m=\u001B[39mattention_mask)\n\u001B[0;32m     21\u001B[0m         logits \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mlogits\n\u001B[1;32m---> 23\u001B[0m         all_logits\u001B[38;5;241m.\u001B[39mappend(logits\u001B[38;5;241m.\u001B[39mcpu())  \u001B[38;5;66;03m# move back to CPU for later stacking\u001B[39;00m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;66;03m# 4. Stack all logits\u001B[39;00m\n\u001B[0;32m     26\u001B[0m logits \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat(all_logits)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "all_logits = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Predicting\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        all_logits.append(logits.cpu())  # move back to CPU for later stacking\n",
    "\n",
    "logits = torch.cat(all_logits)\n",
    "\n",
    "Y_true = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "faf4cc01-f16d-45dc-ac51-1113b1bae836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0: Best threshold = 0.79, Best F1 = 0.6990\n",
      "Label 1: Best threshold = 0.44, Best F1 = 0.4326\n",
      "Label 2: Best threshold = 0.79, Best F1 = 0.7084\n",
      "Label 3: Best threshold = 0.50, Best F1 = 0.0000\n",
      "Label 4: Best threshold = 0.66, Best F1 = 0.6607\n",
      "Label 5: Best threshold = 0.30, Best F1 = 0.1550\n",
      "\n",
      "Best thresholds per label: [0.7900000000000005, 0.4400000000000001, 0.7900000000000005, 0.5, 0.6600000000000004, 0.3]\n"
     ]
    }
   ],
   "source": [
    "# Convert to probabilities\n",
    "\n",
    "probs = torch.sigmoid(logits).cpu().numpy()\n",
    "\n",
    "# Find the best threshold for each lable\n",
    "\n",
    "num_labels = probs.shape[1]\n",
    "best_thresholds = []\n",
    "\n",
    "for label_idx in range(num_labels):\n",
    "    best_f1 = 0\n",
    "    best_thresh = 0.5  # default starting value\n",
    "\n",
    "    for threshold in np.arange(0.3, 0.8, 0.01):\n",
    "        preds = (probs[:, label_idx] > threshold).astype(int)\n",
    "        f1 = f1_score(Y_true[:, label_idx], preds, zero_division=0)\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_thresh = threshold\n",
    "\n",
    "    best_thresholds.append(best_thresh)\n",
    "    print(f\"Label {label_idx}: Best threshold = {best_thresh:.2f}, Best F1 = {best_f1:.4f}\")\n",
    "\n",
    "print(\"\\nBest thresholds per label:\", best_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fb0f5362-308c-44c1-80c8-987ad7417e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1: 0.6635\n",
      "Macro F1: 0.4426\n",
      "Micro Precision: 0.6440\n",
      "Macro Precision: 0.4905\n",
      "Micro Recall: 0.6841\n",
      "Macro Recall: 0.4623\n"
     ]
    }
   ],
   "source": [
    "final_preds = np.zeros_like(probs)\n",
    "\n",
    "for label_idx in range(probs.shape[1]):\n",
    "    final_preds[:, label_idx] = (probs[:, label_idx] > best_thresholds[label_idx]).astype(int)\n",
    "\n",
    "\n",
    "# Evaluate the results\n",
    "micro_f1 = f1_score(Y_true, final_preds, average='micro', zero_division=0)\n",
    "macro_f1 = f1_score(Y_true, final_preds, average='macro', zero_division=0)\n",
    "micro_precision = precision_score(Y_true, final_preds, average='micro', zero_division=0)\n",
    "macro_precision = precision_score(Y_true, final_preds, average='macro', zero_division=0)\n",
    "micro_recall = recall_score(Y_true, final_preds, average='micro', zero_division=0)\n",
    "macro_recall = recall_score(Y_true, final_preds, average='macro', zero_division=0)\n",
    "\n",
    "print(f\"Micro F1: {micro_f1:.4f}\")\n",
    "print(f\"Macro F1: {macro_f1:.4f}\")\n",
    "print(f\"Micro Precision: {micro_precision:.4f}\")\n",
    "print(f\"Macro Precision: {macro_precision:.4f}\")\n",
    "print(f\"Micro Recall: {micro_recall:.4f}\")\n",
    "print(f\"Macro Recall: {macro_recall:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hateBERT)",
   "language": "python",
   "name": "hatebert-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
